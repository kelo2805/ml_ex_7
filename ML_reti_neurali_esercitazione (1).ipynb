{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c5d08680",
      "metadata": {
        "id": "c5d08680"
      },
      "source": [
        "# **Reti Neurali**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52a5f30f",
      "metadata": {
        "id": "52a5f30f"
      },
      "source": [
        "## **Esercizio 1: Download e pre-processamento dei dati.**\n",
        "\n",
        "Scaricare e pre-processare i dati per il successivo addestramento del modello.\n",
        "\n",
        "Il dataset che utilizzeremo sarà CIFAR10, scaricabile dalla libreria `tensorflow.keras.datasets`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42e9791d",
      "metadata": {
        "id": "42e9791d"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "# Download dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "y_train = y_train.ravel()\n",
        "y_test = y_test.ravel()\n",
        "\n",
        "# Stampare le shape dei dati\n",
        "\n",
        "print(\"Shape x_train:\", x_train.shape)\n",
        "print(\"Shape y_train:\", y_train.shape)\n",
        "print(\"Shape x_test:\", x_test.shape)\n",
        "print(\"Shape y_test:\", y_test.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d6a0ca6",
      "metadata": {
        "id": "4d6a0ca6"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Pre-processamento dei dati\n",
        "\n",
        "# svolgimento...\n",
        "\n",
        "x_train_flat = x_train.reshape((x_train.shape[0], -1))  # (50000, 3072)\n",
        "x_test_flat = x_test.reshape((x_test.shape[0], -1))     # (10000, 3072)\n",
        "\n",
        "# Inizializzazione dello StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Adattamento dello scaler ai dati di addestramento\n",
        "x_train_scaled = scaler.fit_transform(x_train_flat)\n",
        "\n",
        "# Applicazione della trasformazione ai dati di test\n",
        "x_test_scaled = scaler.transform(x_test_flat)\n",
        "\n",
        "# Visualizzazione delle nuove shape\n",
        "print(\"Shape x_train_scaled:\", x_train_scaled.shape)\n",
        "print(\"Shape x_test_scaled:\", x_test_scaled.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5103ad7f",
      "metadata": {
        "id": "5103ad7f"
      },
      "source": [
        "## **Esercizio 2: Creare modello MLP**\n",
        "\n",
        "Per creare il modello MLP utilizziamo l' oggetto `MLPClassifier` dal modulo `sklearn.neural_networks`. Questo è un oggetto molto complesso che prevede la possibilità di specificare tanti parametri, permettendoci una personalizzazione molto dettagliata. Vediamo di seguito gli argomenti principali:\n",
        "\n",
        "- `hidden_layer_sizes`: rappresenta la struttura dell' MLP, sotto forma di una tupla. La tupla deve essere composta da numeri interi, ogni numero indica il numero di neuroni presenti nel rispettivo layer.\n",
        "\n",
        "Esempio:\n",
        "\n",
        "`hidden_layer_sizes` = `(100)`\n",
        "\n",
        "creerà un solo layer con 100 neuroni\n",
        "\n",
        "`hidden_layer_sizes` = `(100, 50)`\n",
        "\n",
        "creerà due layer, il primo con 100 neuroni, il secondo invece con 50.\n",
        "\n",
        "- `max_iter`: massimo numero di iterazioni per raggiungere la convergenza.\n",
        "\n",
        "- `activation`: indica quale funzione di attivazione utilizzare, valori possibili sono `'relu'`, `'logistic'`, `'tanh'` and `'identity'`.\n",
        "\n",
        "- `solver`: indica quale algoritmo di ottimizzazione utilizzare, valori possibili sono `'adam'`, `'sgd'` and `'lbfgs'`.\n",
        "\n",
        "- `learning_rate_init`: valore iniziale del learning rate.\n",
        "\n",
        "- `verbose`: valore booleano che, se impostato su `True`, stampa l' output di ogni iterazione di training. Molto utile per monitorare il training.\n",
        "\n",
        "- `random_state`: fissa il seed della randomizzazione.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0f857d0",
      "metadata": {
        "id": "b0f857d0"
      },
      "source": [
        "Per iniziare creiamo un MLP molto basilare, alleniamolo e testiamone le performance. Come parametri utilizzeremo:\n",
        "\n",
        "- `hidden_layer_sizes` = `(100)`\n",
        "\n",
        "- `max_iter` = `20`\n",
        "\n",
        "- `random_state` = `42`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4650894a",
      "metadata": {
        "id": "4650894a"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Creare MLP\n",
        "\n",
        "# svolgimento...\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100), max_iter=20, random_state=42, verbose=True)\n",
        "\n",
        "# Allenare MLP\n",
        "\n",
        "# svolgimento...\n",
        "mlp.fit(x_train_scaled, y_train)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Valutare MLP\n",
        "\n",
        "# svolgimento...\n",
        "\n",
        "y_pred = mlp.predict(x_test_scaled)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "\n",
        "# Stampare l' accuratezza\n",
        "\n",
        "# svolgimento...\n",
        "print(\"Accuratezza sul test set:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6171280e",
      "metadata": {
        "id": "6171280e"
      },
      "source": [
        "## **Esercizio 2.1: Aumentiamo i parametri del nostro modello**\n",
        "\n",
        "Proviamo adesso ad aumentare i dettagli del nostro modello, modificando o aggiungendo i parametri sopra specificati."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f35afa68",
      "metadata": {
        "id": "f35afa68"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Creare MLP con più strati e altre specifiche\n",
        "\n",
        "# svolgimento...\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Creazione di un MLP più complesso\n",
        "mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=(512, 256, 128),  # Tre layer nascosti con neuroni decrescenti\n",
        "    activation='relu',                  # Funzione di attivazione\n",
        "    solver='adam',                      # Ottimizzatore\n",
        "    learning_rate_init=0.001,           # Learning rate iniziale\n",
        "    max_iter=50,                        # Numero massimo di iterazioni\n",
        "    random_state=42,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Addestramento del modello\n",
        "mlp.fit(x_train_scaled, y_train)\n",
        "\n",
        "# Predizione sui dati di test\n",
        "y_pred = mlp.predict(x_test_scaled)\n",
        "\n",
        "# Calcolo dell'accuratezza\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Stampa dell'accuratezza\n",
        "print(\"Accuratezza sul test set:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "226b1681",
      "metadata": {
        "id": "226b1681"
      },
      "source": [
        "## **Esercizio 3: Implementare manualmente l' algoritmo di early stopping.**\n",
        "\n",
        "L' algoritmo di early stopping ci permette di terminare anticipatamente l' allenamento di un modello nel caso in cui questo raggiunga la convergenza. Supponiamo infatti che il nostro modello raggiunga un certo livello di accuratezza e che non riesca a migliorare oltre quel livello. Questo significa che il modello, da quel momento in poi, non sta più apprendendo nuove informazioni, per cui le successive iterazioni sono superflue, ed inoltre rischiano di essere dannose, spingendo il modello verso l' overfitting.\n",
        "\n",
        "L' early stopping verifica ad ogni iterazione che l' accuratezza del modello sia incrementata di una certa tolleranza. Se questa tolleranza non viene superata per un certo numero di epoche, allora possiamo decidere di stoppare l' allenamento in quanto il modello ha raggiunto la convergenza.\n",
        "\n",
        "**N.B: per applicare early stopping è necessario specificare i seguenti parametri dell' MLP:**\n",
        "\n",
        "- `warm_start`=`True` in modo che il training proceda dallo stato attuale del modello e non dall' inizializzazione.\n",
        "\n",
        "- `max_iter`=`1` in modo che il modello venga allenato per una sola epoca. Per l' early stopping infatti dovremo gestire manualmente il numero di iterazioni."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ee1709d",
      "metadata": {
        "id": "8ee1709d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "n_total_epochs = 100\n",
        "patience = 10\n",
        "tolerance = 1e-4\n",
        "\n",
        "best_test_accuracy = 0.0\n",
        "epochs_without_improvement = 0\n",
        "\n",
        "\n",
        "#svolgimento:\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#nota: È una buona pratica usare un validation set separato per applicare l’early stopping, così da evitare l’overfitting ai dati di test.\n",
        "# Splitting del training set in training + validation\n",
        "X_train, X_val, y_train_split, y_val = train_test_split(\n",
        "    x_train_scaled, y_train, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Parametri early stopping\n",
        "n_total_epochs = 100\n",
        "patience = 10\n",
        "tolerance = 1e-4\n",
        "\n",
        "# Inizializzazione\n",
        "best_val_accuracy = 0.0\n",
        "epochs_without_improvement = 0\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "\n",
        "# Modello MLP con warm start\n",
        "mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=(512, 256, 128),\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    learning_rate_init=0.001,\n",
        "    max_iter=1,\n",
        "    warm_start=True,\n",
        "    random_state=42,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "# Ciclo di addestramento\n",
        "for epoch in range(n_total_epochs):\n",
        "    mlp.fit(X_train, y_train_split)\n",
        "\n",
        "    # Valutazione su train e validation\n",
        "    train_acc = accuracy_score(y_train_split, mlp.predict(X_train))\n",
        "    val_acc = accuracy_score(y_val, mlp.predict(X_val))\n",
        "\n",
        "    train_accuracies.append(train_acc)\n",
        "    val_accuracies.append(val_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1} - Train Accuracy: {train_acc:.4f}, Val Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "    # Early stopping\n",
        "    if val_acc > best_val_accuracy + tolerance:\n",
        "        best_val_accuracy = val_acc\n",
        "        epochs_without_improvement = 0\n",
        "    else:\n",
        "        epochs_without_improvement += 1\n",
        "\n",
        "    if epochs_without_improvement >= patience:\n",
        "        print(f\"\\nEarly stopping a epoch {epoch+1}\")\n",
        "        break\n",
        "\n",
        "# Valutazione finale su test set\n",
        "y_test_pred = mlp.predict(x_test_scaled)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print(f\"\\nAccuratezza finale sul test set: {test_accuracy:.4f}\")\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ddace1e",
      "metadata": {
        "id": "9ddace1e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pytorchenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}